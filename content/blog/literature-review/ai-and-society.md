---
title: 'Artificial Intelligence and Society'
date: 2019-11-22 13:11:11
category: 'literature review'
---

Artificial intelligence and machine learning applications are becoming more common and an increasing amount of everyday users are beginning to 'rely on them to deal with a variety of tasks' (Taddeo and Floridi, 2018, p.751), the technology 'is already reshaping our lives, our interactions, and our environments' (Floridi et al 2018a, p.689). The uses of artifical intellegence and machine learning vary dramaticly within new media from popular voice assistants, to language learning apps such as ELSA speak, to an app that predicts crime rates in Rio de Janerio neibourhoods (Griffiths, 2016). Thus it is important to explore the societal impacts, such as exclusion, work delegation and data governance, from these types of applications and how the development of Kerbit can be driven by these.

### AI and exclusionary data

AI and machine learning technologies can be argued to reinforce the digital divide and in turn introduce new forms of exclusion (Bughin et al, 2018). With mainly western countries being the leaders in artificial intelligence development and training which has the potential to for other countries and cultures to be 'radically underrepresented in the datasets central to developing AI systems' (Hagerty and Rubinov, 2019, p.14). Consequences of this underrepresentation can be seen in events such as discriminatory algorithims in new media FinTech resulting in Latin and African Americans being charged more in mortgage interest (Bartlett et al 2018) and reported 'bias regarding race, gender, and/or sexual orientation in' (Hagerty and Rubinov, 2019, p.12) AI systems. Western-centric datasets and modelling can amplify inequalities already experienced within society.

While upon first glance this exclusion of peoples from Kerbit's dataset may not seem an issues, with the data consisting of recyclable materials and being specifically targetted at Leeds residents thus not needing diversity within the data. However, the representation of different cultures will also be important to Kerbit's AI. For instance, there are ecpected use cases where different cultural factors will need to be analysed by Kerbit, such as being able to recognise packaging no matter what language is on the packaing and different skin tones will need to be understood for when people hold items in the image that Kerbit will analyse. These types of variations in data will help ensure a breadth of understanding from the machine learning model.

### Delegation through artificial intelligence

Delegating tasks to AI can result in societal benefits such as lowering costs and increasing relibility (Taddeo and Floridi, 2018a), for instance machine learning has been used to recognise and shut down system attacks on IT networks with responses faster than human opertors (Taddeo and Floridi 2018b). However this delegation brings into questions the place of human responsibility when choices have been made by a machine. The issue of human responsibily of artificial intelligence can be seen in the tool COMPAS. It was used for assessing the likelihood of a criminal to reoffend and thus effect their chance at parole, however, it was found that 'black defendants were far more likely that white defendants to be ... judeged to be at a higher risk' (Larson et al, 2016) of re-offending. Cases like these show how the reliance on algorithms for decision-making can be harmful to people and why human oversight and responsibility is necessary to minimise any negative impacts of AI.

While Kerbit will not be responsible for as sensitive decision as COMPAS, there are other risks such as environmental ones in the unavoidable eventuallity that Kerbit will get something wrong. Because of this is important to implement the addition of human oversight throughout and official sources of information. To aid in the oversight of Kerbit, an aim for the app is that users will be able to report when Kerbit has predicted something incorrecting so that retraining can be implemented to help the accuracy of the model. Additionally, the constant implementation of official sources of information will be added into the app to give users the ability to double check any information Kerbit has given or learn more. This will include the use of open datasets developed in conjunction with the council to ensure the displaying of appropriate recycling sites and giving the user links to the council site for more information about recycling.

##Â References

Taddeo, M, and Floridi, L. 2018a. How AI can be a force for good. _Science_. **361**(6404), pp.751-752

Taddeo, M, and Floridi, L. 2018b. _Regulate artifical intelligence to avert cyber arms race_.[Online]. [Accessed 20 Feburary 2020]. Avaliable from: https://www.nature.com/articles/d41586-018-04602-6/

Floridi, L., Cowls, J., Beltramentti, M., Chatila, R., Chazerand, P., Dignum, V., Luetge, C., Madelin, R., Pagallo, U., Rossi, F., Schafer, B., Valcke, P and Vayena, E. 2018. AI4People - An Ethical Framework for a Good AI Society: Opportunities, Risks, Priniciples, and Recommendations. _Minds and Machines_. **28**(1), pp. 689-707

Larson, J., Mattu, S., Kirchner, L. and Angwin, J. _How We Analyzed the COMPAS recidivism algorithm_. [Online]. [Accessed 16 Feburary]. Available from: https://www.propublica.org/article/how-we-analyzed-the-compas-recidivism-algorithm

Griffiths, S. 2016. _CrimeRadar is using machine learning to predict crime Rio_. [Online]. [Accessed 16 Feburary 2020]. Available from: https://www.wired.co.uk/article/crimeradar-rio-app-predict-crime

Bughin, J., Seong, J., Manyika, J., Chui, M, and Joshi, R. 2018. \_Notes from the AI frontier: Modeling the impact of AI on the world economy. [Online]. [Accessed 18 Feburary 2020]. Available from: https://www.mckinsey.com/~/media/McKinsey/Featured%20Insights/Artificial%20Intelligence/Notes%20from%20the%20frontier%20Modeling%20the%20impact%20of%20AI%20on%20the%20world%20economy/MGI-Notes-from-the-AI-frontier-Modeling-the-impact-of-AI-on-the-world-economy-September-2018.ashx

Hagerty, A, and Rubinov, I. 2019. Global AI Ethics: A Review of the Social Impacts and Ethical Implications of Artificial Intelligence. _CoRR_. **1**(No issue) pp. 1-27

Bartlett, R., Morse, A., Stanton, R. and Wallace, N. 2018. _Consumer Lending Discrimination in the FinTech Era_. [Online]. Working paper. [Accessed 17 Feburary 2020]. Available from: https://www.aeaweb.org/conference/2019/preliminary/paper/YEN76Dh2
